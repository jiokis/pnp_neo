import torch
import csv
import os
from datetime import datetime


class PyramidMonitor:
    """ç‰¹å¾é‡‘å­—å¡”è®­ç»ƒç›‘æ§å™¨ï¼šå®æ—¶è·Ÿè¸ªå‚æ•°æ›´æ–°ã€æ€§èƒ½å¢ç›Šï¼Œç”Ÿæˆç›‘æ§æ—¥å¿—"""

    def __init__(self, model, log_path="./logs/pyramid_monitor.csv"):
        self.model = model
        self.log_path = log_path
        self.pyramid_params = self._get_pyramid_params()  # è®°å½•é‡‘å­—å¡”æ¨¡å—å‚æ•°å
        self.init_pyramid_weights = self._save_init_weights()  # ä¿å­˜åˆå§‹æƒé‡ï¼ˆç”¨äºè®¡ç®—æ›´æ–°é‡ï¼‰
        self._init_log_file()  # åˆå§‹åŒ–ç›‘æ§æ—¥å¿—æ–‡ä»¶

    def _get_pyramid_params(self):
        """è·å–ç‰¹å¾é‡‘å­—å¡”æ¨¡å—çš„æ‰€æœ‰å‚æ•°åï¼ˆè¿‡æ»¤å…¶ä»–æ¨¡å—ï¼‰"""
        pyramid_param_names = []
        for name, _ in self.model.named_parameters():
            # åŒ¹é…ç‰¹å¾é‡‘å­—å¡”æ¨¡å—çš„å‚æ•°ï¼ˆå¯¹åº”appearance_branchä¸­çš„pyramidå±‚ï¼‰
            if "backbone.appearance_branch.pyramid" in name:
                pyramid_param_names.append(name)
        return pyramid_param_names

    def _save_init_weights(self):
        """ä¿å­˜ç‰¹å¾é‡‘å­—å¡”æ¨¡å—çš„åˆå§‹æƒé‡ï¼ˆç”¨äºåç»­è®¡ç®—å‚æ•°å˜åŒ–ï¼‰"""
        init_weights = {}
        for name in self.pyramid_params:
            param = dict(self.model.named_parameters())[name]
            init_weights[name] = param.data.clone().detach()
        return init_weights

    def _init_log_file(self):
        """åˆå§‹åŒ–ç›‘æ§æ—¥å¿—æ–‡ä»¶ï¼Œå†™å…¥è¡¨å¤´"""
        log_dir = os.path.dirname(self.log_path)
        if not os.path.exists(log_dir):
            os.makedirs(log_dir)

        # è‹¥æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå†™å…¥è¡¨å¤´
        if not os.path.exists(self.log_path):
            with open(self.log_path, "w", newline="", encoding="utf-8") as f:
                writer = csv.writer(f)
                writer.writerow([
                    "datetime", "epoch",
                    "pyramid_param_update_ratio",  # é‡‘å­—å¡”å‚æ•°æ›´æ–°æ¯”ä¾‹
                    "train_loss_change",  # è®­ç»ƒæŸå¤±å˜åŒ–ï¼ˆç›¸å¯¹ä¸Šä¸€è½®ï¼‰
                    "val_loss_change",  # éªŒè¯æŸå¤±å˜åŒ–ï¼ˆç›¸å¯¹ä¸Šä¸€è½®ï¼‰
                    "key_metric_change"  # å…³é”®æŒ‡æ ‡å˜åŒ–ï¼ˆå¦‚AUC/å‡†ç¡®ç‡ï¼‰
                ])

    def _calc_param_update_ratio(self):
        """è®¡ç®—ç‰¹å¾é‡‘å­—å¡”å‚æ•°çš„æ›´æ–°æ¯”ä¾‹ï¼ˆL2èŒƒæ•°ç›¸å¯¹åˆå§‹æƒé‡çš„å˜åŒ–ï¼‰"""
        if not self.pyramid_params:
            return 0.0

        total_update = 0.0
        total_init = 0.0
        for name in self.pyramid_params:
            current_param = dict(self.model.named_parameters())[name].data
            init_param = self.init_pyramid_weights[name]

            # è®¡ç®—L2èŒƒæ•°
            update_norm = torch.norm(current_param - init_param).item()
            init_norm = torch.norm(init_param).item()

            total_update += update_norm
            total_init += init_norm

        # é¿å…é™¤ä»¥0ï¼ˆåˆå§‹æƒé‡å…¨0æ—¶ï¼‰
        return total_update / total_init if total_init > 1e-8 else 0.0

    def monitor_epoch(self, epoch, train_loss, train_metrics, val_loss=None, val_metrics=None):
        """æ¯è½®epochç»“æŸåï¼Œè®°å½•ç›‘æ§æ•°æ®"""
        # 1. è®¡ç®—é‡‘å­—å¡”å‚æ•°æ›´æ–°æ¯”ä¾‹
        update_ratio = self._calc_param_update_ratio()

        # 2. è®¡ç®—æŸå¤±/æŒ‡æ ‡å˜åŒ–ï¼ˆç›¸å¯¹ä¸Šä¸€è½®ï¼Œé¦–æ¬¡epochè®°ä¸º0ï¼‰
        if epoch == 1:
            train_loss_change = 0.0
            val_loss_change = 0.0
            key_metric_change = 0.0
        else:
            # è¯»å–ä¸Šä¸€è½®æ—¥å¿—æ•°æ®
            with open(self.log_path, "r", encoding="utf-8") as f:
                reader = csv.reader(f)
                last_row = list(reader)[-1]  # æœ€åä¸€è¡Œæ˜¯ä¸Šä¸€è½®æ•°æ®

            # è®­ç»ƒæŸå¤±å˜åŒ–ï¼ˆå½“å‰ - ä¸Šä¸€è½®ï¼‰
            train_loss_change = train_loss["total_loss"] - float(last_row[2])
            # éªŒè¯æŸå¤±å˜åŒ–
            val_loss_change = val_loss["total_loss"] - float(last_row[3]) if val_loss else 0.0
            # å…³é”®æŒ‡æ ‡å˜åŒ–ï¼ˆå‡è®¾ç”¨ç¬¬ä¸€ä¸ªæŒ‡æ ‡ï¼Œå¦‚å‡†ç¡®ç‡/aucï¼Œå½“å‰ - ä¸Šä¸€è½®ï¼‰
            key_metric = list(train_metrics.values())[0] if train_metrics else 0.0
            key_metric_change = key_metric - float(last_row[4])

        # 3. å†™å…¥æ—¥å¿—
        with open(self.log_path, "a", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow([
                datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                epoch,
                round(update_ratio, 6),
                round(train_loss_change, 4),
                round(val_loss_change, 4) if val_loss else 0.0,
                round(key_metric_change, 4)
            ])

        # 4. æ‰“å°å®æ—¶ç›‘æ§ä¿¡æ¯ï¼ˆç»ˆç«¯è¾“å‡ºï¼Œæ–¹ä¾¿æŸ¥çœ‹ï¼‰
        print(f"\nğŸ“Š ç‰¹å¾é‡‘å­—å¡”ç›‘æ§ï¼ˆEpoch {epoch}ï¼‰:")
        print(f"   - å‚æ•°æ›´æ–°æ¯”ä¾‹: {update_ratio:.6f}ï¼ˆ>0è¡¨ç¤ºæ¨¡å—æ­£åœ¨è®­ç»ƒï¼‰")
        print(f"   - è®­ç»ƒæŸå¤±å˜åŒ–: {train_loss_change:.4f}ï¼ˆè´Ÿå€¼è¡¨ç¤ºä¸‹é™ï¼‰")
        if val_loss:
            print(f"   - éªŒè¯æŸå¤±å˜åŒ–: {val_loss_change:.4f}ï¼ˆè´Ÿå€¼è¡¨ç¤ºä¸‹é™ï¼‰")
        print(f"   - å…³é”®æŒ‡æ ‡å˜åŒ–: {key_metric_change:.4f}ï¼ˆæ­£å€¼è¡¨ç¤ºæå‡ï¼‰")

    def get_summary(self):
        """è·å–è®­ç»ƒè‡³ä»Šçš„ç›‘æ§æ€»ç»“"""
        with open(self.log_path, "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            rows = list(reader)[1:]  # è·³è¿‡è¡¨å¤´

        total_epochs = len(rows)
        final_update_ratio = float(rows[-1][1]) if total_epochs > 0 else 0.0
        final_train_loss = float(rows[-1][2]) if total_epochs > 0 else 0.0
        final_val_loss = float(rows[-1][3]) if total_epochs > 0 else 0.0

        summary = f"""
        ğŸ“ˆ ç‰¹å¾é‡‘å­—å¡”è®­ç»ƒç›‘æ§æ€»ç»“ï¼ˆå…±{total_epochs}è½®ï¼‰:
        - æœ€ç»ˆå‚æ•°æ›´æ–°æ¯”ä¾‹: {final_update_ratio:.6f}
        - æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train_loss:.4f}
        - æœ€ç»ˆéªŒè¯æŸå¤±: {final_val_loss:.4f}
        - æ¨¡å—è®­ç»ƒæœ‰æ•ˆæ€§: {'âœ… æœ‰æ•ˆï¼ˆå‚æ•°æ›´æ–°æ­£å¸¸ï¼‰' if final_update_ratio > 1e-6 else 'âŒ æ— æ•ˆï¼ˆå‚æ•°æœªæ›´æ–°ï¼‰'}
        """
        print(summary)
        return summary